# ğŸš€ E-Commerce Data Warehouse & ETL Pipeline

![Python](https://img.shields.io/badge/Python-3.9-blue?logo=python&logoColor=white)
![Docker](https://img.shields.io/badge/Docker-2496ED?logo=docker&logoColor=white)
![Airflow](https://img.shields.io/badge/Apache%20Airflow-017CEE?logo=apache-airflow&logoColor=white)
![PostgreSQL](https://img.shields.io/badge/PostgreSQL-4169E1?logo=postgresql&logoColor=white)
![Power BI](https://img.shields.io/badge/Power%20BI-F2C811?logo=power-bi&logoColor=black)

ğŸ“– Overview

Bu proje, ham ve karmaÅŸÄ±k e-ticaret verilerini (CSV) alarak tamamen temizlenmiÅŸ, optimize edilmiÅŸ ve analitik iÅŸlemlere uygun bir Veri AmbarÄ± (Data Warehouse) yapÄ±sÄ±na dÃ¶nÃ¼ÅŸtÃ¼ren uÃ§tan uca bir ETL Pipeline uygulamasÄ±dÄ±r.

Proje kapsamÄ±nda:

- Extract â€“ CSV dosyalarÄ±ndan veri Ã§ekme
- Transform â€“ Temizleme, dÃ¼zenleme, normalizasyon, tip dÃ¶nÃ¼ÅŸÃ¼mleri
- Load â€“ PostgreSQL Ã¼zerinde Kimball'a uygun Star Schemaâ€™ya yÃ¼kleme
- Orchestrate â€“ Airflow Ã¼zerinde otomatik zamanlama ve task yÃ¶netimi
- Visualize â€“ Power BI ile interaktif dashboard oluÅŸturma
  tamamen otomatik, tekrarlanabilir ve sÃ¼rdÃ¼rÃ¼lebilir bir mimari ile uygulanmÄ±ÅŸtÄ±r.

## ğŸ§  Architecture

### Modern Data Stack

Bu proje modern veri mÃ¼hendisliÄŸi standartlarÄ±na gÃ¶re tasarlanmÄ±ÅŸtÄ±r.

```mermaid
graph LR
    A[ğŸ“„ Raw Data (CSV Files)] -->|Extract| B(ğŸ Python ETL Scripts)
    B -->|Transform| B
    B -->|Load| C[(ğŸ˜ PostgreSQL Data Warehouse)]
    C -->|Query| D[ğŸ“Š Power BI Reports]

    subgraph ğŸ³ Dockerized Environment
        B
        C
        E[ğŸŒ¬ï¸ Apache Airflow Scheduler] -.->|Orchestrates| B
    end

```

â“ Teknoloji SeÃ§imleri â€“ Neden Bu AraÃ§lar?
ğŸ³ Docker & Docker Compose

Neden?
â€” Ortam baÄŸÄ±mlÄ±lÄ±klarÄ±nÄ± ortadan kaldÄ±rmak ve projenin her makinede aynÄ± ÅŸekilde Ã§alÄ±ÅŸmasÄ±nÄ± saÄŸlamak.

SonuÃ§:
â€” PostgreSQL, Airflow ve ETL scriptleri tamamen izole containerâ€™larda Ã§alÄ±ÅŸÄ±r.

ğŸŒ¬ï¸ Apache Airflow

Neden?
â€” ETL sÃ¼recinin manuel deÄŸil, otomatik ve hata toleranslÄ± yÃ¶netilmesi iÃ§in.

SonuÃ§:
â€” GÃ¼nlÃ¼k Ã§alÄ±ÅŸan DAG, task baÄŸÄ±mlÄ±lÄ±klarÄ±nÄ± yÃ¶netir, hata durumunda log Ã¼retir.

ğŸ˜ PostgreSQL + Kimball Star Schema

Neden?
â€” Analitik (OLAP) iÅŸlemlerinin hÄ±zlÄ± Ã§alÄ±ÅŸmasÄ±, raporlarÄ±n optimize edilmesi iÃ§in.

SonuÃ§:
â€” Fact ve Dimension tabanlÄ± profesyonel veri ambarÄ± yapÄ±sÄ±.

ğŸ Python (Pandas, SQLAlchemy, Psycopg2)

Neden?
â€” Veri temizliÄŸi, transform iÅŸlemleri ve Bulk Insert iÃ§in en esnek araÃ§.

SonuÃ§:
â€” DÃ¼ÅŸÃ¼k performanslÄ± veriler temizlenir, sÃ¼tun tipleri normalize edilir, hatalÄ± satÄ±rlar ayÄ±klanÄ±r.

ğŸ› ï¸ Tech Stack
Kategori Teknoloji
Dil Python 3.9
Orkestrasyon Apache Airflow 2.7
VeritabanÄ± PostgreSQL 13
Konteyner Docker
BI Power BI
Python KÃ¼tÃ¼phaneleri Pandas, SQLAlchemy, Psycopg2, PyYAML

Data Warehouse Modeli
VeritabanÄ± tasarÄ±mÄ± Star Schema prensibine gÃ¶re modellenmiÅŸtir.
ğŸ§© Tablo YapÄ±larÄ±
Tablo Tipi Tablo AdÄ± AÃ§Ä±klama
Fact fact_order Fiyat, adet, toplam tutar ve satÄ±ÅŸ olaylarÄ±
Dimension dim_customer MÃ¼ÅŸteri bilgileri, Ã¼lke, ID
Dimension dim_product ÃœrÃ¼n adÄ±, stok kodu, aÃ§Ä±klama
Dimension dim_date Zaman analizlerine uygun tarih boyutu

Dashboard

Projenin son Ã§Ä±ktÄ±sÄ± Power BI'da hazÄ±rlanan interaktif analiz raporudur.
reports/ klasÃ¶rÃ¼nde yer alan dashboard ekran gÃ¶rÃ¼ntÃ¼sÃ¼ Ã¶rnek olarak eklenmiÅŸtir.

ğŸš€ Kurulum & Ã‡alÄ±ÅŸtÄ±rma

Bu projeyi Ã§alÄ±ÅŸtÄ±rmak iÃ§in Docker Desktop kurulu olmalÄ±dÄ±r.

ğŸ”½ 1. Projeyi KlonlayÄ±n
git clone https://github.com/YukselUygun/E-Commerce-Data-Warehouse-ETL-Project.git
cd E-Commerce-Data-Warehouse-ETL-Project

ğŸ³ 2. TÃ¼m Sistemi AyaÄŸa KaldÄ±rÄ±n
docker-compose up --build

Bu komut:
PostgreSQLâ€™i oluÅŸturur
Airflow Scheduler & Webserver kurulumunu yapar
ETL ortamÄ±nÄ± hazÄ±r hale getirir

ğŸŒ 3. Airflow ArayÃ¼zÃ¼ne GiriÅŸ

TarayÄ±cÄ±nÄ±zdan:
ğŸ‘‰ http://localhost:8080
KullanÄ±cÄ± adÄ±: admin
Åifre: admin

â–¶ï¸ 4. ETL Pipeline'Ä± Ã‡alÄ±ÅŸtÄ±rÄ±n

1- Airflowâ€™da ecommerce_etl_pipeline DAGâ€™Ä±nÄ± bulun
2- Sol taraftan Unpause (anahtarÄ± aÃ§Ä±n)
3- SaÄŸ Ã¼stten Trigger DAG (â–¶) ile baÅŸlatÄ±n

Proje KlasÃ¶r YapÄ±sÄ±
.
â”œâ”€â”€ config/
â”‚ â””â”€â”€ config.yaml
â”œâ”€â”€ data/
â”‚ â””â”€â”€ raw/
â”‚ â””â”€â”€ online_retail.csv
â”œâ”€â”€ etl/
â”‚ â”œâ”€â”€ extract.py
â”‚ â”œâ”€â”€ transform.py
â”‚ â”œâ”€â”€ load.py
â”‚ â””â”€â”€ quality_checks.py
â”œâ”€â”€ dags/
â”‚ â””â”€â”€ ecommerce_etl_pipeline.py
â”œâ”€â”€ logs/
â”œâ”€â”€ docker-compose.yml
â””â”€â”€ reports/

ğŸ§ª Veri Kalitesi Kontrolleri (Data Quality Checks)

Pipeline sonunda otomatik kalite kontrolleri uygulanÄ±r:

- Null kontrolÃ¼
- Tip dÃ¶nÃ¼ÅŸÃ¼m kontrolÃ¼
- Negatif deÄŸer kontrolÃ¼
- Duplicate satÄ±r kontrolÃ¼
- Factâ€“Dimension foreign key uyumluluÄŸu
- Hatalar loglara yazÄ±lÄ±r.

ğŸ‘¨â€ğŸ’» GeliÅŸtirici

YÃ¼ksel Uygun
ğŸ”— LinkedIn: (https://www.linkedin.com/in/yukseluygun/)
